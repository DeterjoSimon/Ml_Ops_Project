Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch:   0%|                                            | 0/5 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "src/models/train_model.py", line 44, in <module>
    for step, batch in enumerate(train_dataloader):
  File "/zhome/22/4/118839/Ml_Ops_Project/Venv/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 289, in __iter__
    return _SingleProcessDataLoaderIter(self)
  File "/zhome/22/4/118839/Ml_Ops_Project/Venv/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 394, in __init__
    super(_SingleProcessDataLoaderIter, self).__init__(loader)
  File "/zhome/22/4/118839/Ml_Ops_Project/Venv/lib64/python3.6/site-packages/torch/utils/data/dataloader.py", line 350, in __init__
    self._base_seed = torch.empty((), dtype=torch.int64).random_(generator=loader.generator).item()
AttributeError: 'DataLoader' object has no attribute 'generator'
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
~/Ml_Ops_Project/src/models/train_model.py in <module>
     42   model.zero_grad()
     43
---> 44   for step, batch in enumerate(train_dataloader):
     45
     46       input_ids = batch[0].to(device)
~/Ml_Ops_Project/Venv/lib64/python3.6/site-packages/torch/utils/data/dataloader.py in __iter__(self)
    287     def __iter__(self):
    288         if self.num_workers == 0:
--> 289             return _SingleProcessDataLoaderIter(self)
    290         else:
    291             return _MultiProcessingDataLoaderIter(self)
~/Ml_Ops_Project/Venv/lib64/python3.6/site-packages/torch/utils/data/dataloader.py in __init__(self, loader)
    392 class _SingleProcessDataLoaderIter(_BaseDataLoaderIter):
    393     def __init__(self, loader):
--> 394         super(_SingleProcessDataLoaderIter, self).__init__(loader)
    395         assert self._timeout == 0
    396         assert self._num_workers == 0
~/Ml_Ops_Project/Venv/lib64/python3.6/site-packages/torch/utils/data/dataloader.py in __init__(self, loader)
    348         self._collate_fn = loader.collate_fn
    349         self._sampler_iter = iter(self._index_sampler)
--> 350         self._base_seed = torch.empty((), dtype=torch.int64).random_(generator=loader.generator).item()
    351         self._num_yielded = 0
    352
AttributeError: 'DataLoader' object has no attribute 'generator'